{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f44bc07d-be58-40b9-a938-69ac5afaec90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f44bc07d-be58-40b9-a938-69ac5afaec90",
    "outputId": "75d434a3-7994-4879-8c15-6413db5ace33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers datasets accelerate huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32848692-4014-431b-b900-a2369546b5fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82202b19-b779-4d95-affa-15693da888a3",
   "metadata": {
    "id": "82202b19-b779-4d95-affa-15693da888a3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c276e02f-9740-423c-96c9-14df9635800b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c276e02f-9740-423c-96c9-14df9635800b",
    "outputId": "55f04769-3991-4e1e-a42c-2b99fe80c7e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter huggingface token ········\n"
     ]
    }
   ],
   "source": [
    "token = getpass(prompt=\"enter huggingface token\")\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef0379f1-9c86-4d5f-8ef4-757c65d87b49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef0379f1-9c86-4d5f-8ef4-757c65d87b49",
    "outputId": "ddcc5476-e9ec-4e68-d622-63da69c02536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 180 rows in the dataset\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"data\"\n",
    "\n",
    "if os.path.isfile(dir_name + '/topics.json'):\n",
    "    with open(dir_name + '/topics.json') as t:\n",
    "        topics = json.load(t)\n",
    "\n",
    "    topics = topics.keys()\n",
    "    tfiles = [dir_name + f\"\"\"/{\"-\".join(t.lower().split(' '))}.json\"\"\" for t in topics]\n",
    "    tfiles = [tf for tf in tfiles if os.path.isfile(tf)]\n",
    "\n",
    "    data = []\n",
    "    for tf in tfiles:\n",
    "        with open(tf) as t:\n",
    "            data.extend(json.load(t))\n",
    "\n",
    "    print(f'there are {len(data)} rows in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3b628c3-5803-4ba9-a0f6-74d8ada72ee8",
   "metadata": {
    "id": "d3b628c3-5803-4ba9-a0f6-74d8ada72ee8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cdc5998-8d51-409a-91b2-410a968c94ea",
   "metadata": {
    "id": "1cdc5998-8d51-409a-91b2-410a968c94ea"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "314243ec-09e7-4005-ae97-9616eedf3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].train_test_split(test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e92ffec3-5e32-4a34-a62d-101ba19fd557",
   "metadata": {
    "id": "e92ffec3-5e32-4a34-a62d-101ba19fd557"
   },
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "    row['input'] = f'<question>\\n{row[\"question\"]}\\n</question>\\n\\n<documents>\\n{row[\"documents\"]}\\n</documents>\\n\\n<answer>'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6324a8a-1845-4f50-ad04-4e5ba4402e95",
   "metadata": {
    "id": "c6324a8a-1845-4f50-ad04-4e5ba4402e95"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65e1b86f-0664-423c-9f2b-bc90a9d32902",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65e1b86f-0664-423c-9f2b-bc90a9d32902",
    "outputId": "25ddc325-4fd1-4d83-87bb-58f2e4cdbd8d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<question>\n",
      "What are the projected rare earth element requirements for achieving global net-zero emissions by 2050?\n",
      "</question>\n",
      "\n",
      "<documents>\n",
      "Document 1: Rare earth elements play a crucial role in the development of green technologies that are essential for reducing carbon emissions. Neodymium and dysprosium are key components in the permanent magnets used in wind turbines, allowing for more efficient electricity generation without mechanical gearboxes. These magnets are also essential in electric vehicle motors, with each EV requiring approximately 1kg of rare earth materials. Additionally, rare earth elements like europium, terbium, and yttrium are used in energy-efficient LED lighting, reducing energy consumption compared to traditional lighting solutions.\n",
      "---\n",
      "Document 2: Demand-side economics for rare earths are driven by growing applications in clean energy, transportation electrification, and advanced electronics. The permanent magnet sector represents the largest value segment, consuming approximately 35% of rare earth oxide volume but accounting for 80% of market value due to the higher prices of magnetic elements like neodymium, praseodymium, dysprosium, and terbium. Demand for these magnetic materials is projected to grow at 8-12% annually through 2030, outpacing supply growth. Meanwhile, cerium and lanthanum, which constitute approximately 60% of typical rare earth deposits, face more modest demand growth and lower prices, creating economic imbalances in the market. Substitution economics also influence market dynamics; in some applications, manufacturers will reformulate products when price ratios between different rare earths or between rare earths and alternatives reach certain thresholds.\n",
      "---\n",
      "Document 3: The transition to renewable energy sources heavily depends on rare earth metals for efficiency and performance. Lanthanum is used in NiMH batteries, which serve as energy storage solutions for hybrid vehicles and grid-scale renewable energy systems. Cerium is employed in catalytic converters that reduce vehicle emissions. Furthermore, samarium-cobalt magnets are utilized in highly efficient electric motors and generators that operate in extreme temperature conditions, making them ideal for certain renewable energy applications where durability is paramount.\n",
      "</documents>\n",
      "\n",
      "<answer>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d49cfde-42ea-450a-8068-3ea15ed912ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d49cfde-42ea-450a-8068-3ea15ed912ec",
    "outputId": "a7efafbd-cc79-4cdc-a186-056bf09c1db8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6821c8a-7fe5-4e44-8f3b-fdc6e7f6a18c",
   "metadata": {
    "id": "b6821c8a-7fe5-4e44-8f3b-fdc6e7f6a18c"
   },
   "outputs": [],
   "source": [
    "# model = model.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c202ab4-67c9-4757-a199-d586daaf1aad",
   "metadata": {
    "id": "0c202ab4-67c9-4757-a199-d586daaf1aad"
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb05f9fc-a385-4267-9f2f-5e1f7b695019",
   "metadata": {
    "id": "fb05f9fc-a385-4267-9f2f-5e1f7b695019"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "    prompt = row[\"input\"]\n",
    "    full_text = prompt + \"\\n\" + f'{row[\"answer\"]}\\n</answer>'\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        full_text,\n",
    "        truncation=True,\n",
    "        max_length=1536,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    prompt_tokenized = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=1536,\n",
    "        add_special_tokens=False  # Ensure no extra tokens are added\n",
    "    )\n",
    "    prompt_length = len(prompt_tokenized[\"input_ids\"])\n",
    "\n",
    "    # Copy the tokenized full text to create labels and mask out prompt tokens\n",
    "    labels = tokenized[\"input_ids\"].copy()\n",
    "    labels[:prompt_length] = [-100] * prompt_length  # -100 tells PyTorch to ignore these tokens in loss computation\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e1df40f-740d-44f7-b1dc-3e2650a9a32c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a33ce0b8245b433089819fecaf8e264e",
      "002ece1cc39743df9cfbaddf4a809c4c",
      "53a453362d8d4133ab4e325e3e34878f",
      "6049807d3ceb4a31920f0b0c1a248f7b",
      "9e41ada6a54447b2a2c6d7c69ba9c645",
      "864f65742b9b4000b165a1bb22f9590c",
      "9783987ada9d43df99911f8eebf20308",
      "71f160de892b4c1ebb25baa54b5614d2",
      "c3527aa4065e448b8a60e105cc395545",
      "e6820a2af9bf44519fa9c4b3c50200a4",
      "bd74c96beddc4ca18c295297ccba750f"
     ]
    },
    "id": "6e1df40f-740d-44f7-b1dc-3e2650a9a32c",
    "outputId": "7ec2de82-4c01-419f-b90f-873e4cf6b6e6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696b580c7e9c41aca93daba1f5c231a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1c94a61e6047dc97368a04dcdfa9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf2af8e2-ae79-4ebb-bc79-7b9add3d0c14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf2af8e2-ae79-4ebb-bc79-7b9add3d0c14",
    "outputId": "e33c16e6-6886-4b4f-d092-fd36a61cf6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 425,984 || all params: 1,236,240,384 || trainable%: 0.0345\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Define LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=4,               # Low-rank dimension\n",
    "    lora_alpha=32,     # Scaling factor\n",
    "    lora_dropout=0.1,  # Dropout for regularization\n",
    "    bias=\"none\",       # No bias training\n",
    "    task_type=\"CAUSAL_LM\"  # Task type: Causal Language Modeling\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "oZSRi7ZP6wIG",
   "metadata": {
    "id": "oZSRi7ZP6wIG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70b1ec-58a3-4a67-96c6-62f9135fbc65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "ab70b1ec-58a3-4a67-96c6-62f9135fbc65",
    "outputId": "d51631b9-ea9e-4ed7-da7f-4e493d0c0cf1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 14:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.253800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.713500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.296900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.284700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.268800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.248300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.204100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.197300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.198500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.197600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.190600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=240, training_loss=0.6859187081456184, metrics={'train_runtime': 869.5274, 'train_samples_per_second': 4.347, 'train_steps_per_second': 0.276, 'total_flos': 3.391582485086208e+16, 'train_loss': 0.6859187081456184, 'epoch': 30.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama-1b-finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=30,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test']\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b42f1dd-f184-452a-bb65-143497f89b8d",
   "metadata": {
    "id": "7b42f1dd-f184-452a-bb65-143497f89b8d"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43529265-c52b-49ae-ada5-802c4d5df9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./llama-1b-finetuned/checkpoint-224\", device=\"cuda\", max_length=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bd6f1fe-18ec-4dc0-ae4b-6b5e7586252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<question>\n",
      "How should we treat animals?\n",
      "</question>\n",
      "\n",
      "<documents>\n",
      "Document 1: But it’s been thirty years and vegans are still less than 10% of the population.If you genuinely care about animal suffering, you have to admit that, and say, ‘what else can we do to ease animal suffering?’”After Singer’s talk, I began thinking through the consequences of his morality.A question occurred to me: “Should we also stop animals from eating each other?” I was sure others had made such arguments as *reductio ad absurdums* of vegetarianism, but I thought I might be the first to be genuinely interested in it from a moral perspective.\n",
      "---\n",
      "Document 2: They didn’t even pretend to make an argument; it was entirely mockery.Watching this, I couldn’t help but realize there was a powerful logical argument at the core of the animal rights groups: animals should be treated much the same way humans are — their lives should be respected, their pain minimized, etc.Make this one simple change to your system of morality and everything else falls into place.\n",
      "---\n",
      "Document 3: But I praise people for the good things they do and condemn them for the bad ones.”A final question raised the incrementalism versus revolutionism debate common to all left-wing social movements.Should one really worry about animal treatment when the animals were still going to be killed?Pinger said the answer was undoubtedly yes.\n",
      "---\n",
      "Document 4: They didn’t even pretend to make an argument; it was entirely mockery.Watching this, I couldn’t help but realize there was a powerful logical argument at the core of the animal rights groups: animals should be treated much the same way humans are — their lives should be respected, their pain minimized, etc.Make this one simple change to your system of morality and everything else falls into place.\n",
      "---\n",
      "Document 5: But I praise people for the good things they do and condemn them for the bad ones.”A final question raised the incrementalism versus revolutionism debate common to all left-wing social movements.Should one really worry about animal treatment when the animals were still going to be killed?Pinger said the answer was undoubtedly yes.\n",
      "---\n",
      "Document 6: But it’s been thirty years and vegans are still less than 10% of the population.If you genuinely care about animal suffering, you have to admit that, and say, ‘what else can we do to ease animal suffering?’”After Singer’s talk, I began thinking through the consequences of his morality.A question occurred to me: “Should we also stop animals from eating each other?” I was sure others had made such arguments as *reductio ad absurdums* of vegetarianism, but I thought I might be the first to be genuinely interested in it from a moral perspective.\n",
      "</documents>\n",
      "\n",
      "<answer> \n",
      "I’m not sure I agree with all of the points made in the document. I think the first point is a mistake. The claim that “animals should be treated much the same way humans are” is not a moral claim. It’s a claim about how to treat animals. It’s a claim about how to treat animals, not about how animals should be treated. The second point is also a mistake. I don’t think it’s a mistake to say that animals should be treated much the same way humans are. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The third point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The fourth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The fifth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The sixth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The seventh point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The eighth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The ninth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The tenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The eleventh point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The twelfth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The thirteenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The fourteenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The fifteenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The sixteenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The seventeenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The eighteenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The nineteenth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake to say that animals should be treated much the same way humans are. The twentieth point is a mistake. I think it’s a mistake to say that animals should be treated much the same way humans are, but it’s a mistake\n"
     ]
    }
   ],
   "source": [
    "response = pipe(\n",
    "    \"\"\"\n",
    "<question>\n",
    "How should we treat animals?\n",
    "</question>\n",
    "\n",
    "<documents>\n",
    "Document 1: But it’s been thirty years and vegans are still less than 10% of the population.If you genuinely care about animal suffering, you have to admit that, and say, ‘what else can we do to ease animal suffering?’”After Singer’s talk, I began thinking through the consequences of his morality.A question occurred to me: “Should we also stop animals from eating each other?” I was sure others had made such arguments as *reductio ad absurdums* of vegetarianism, but I thought I might be the first to be genuinely interested in it from a moral perspective.\n",
    "---\n",
    "Document 2: They didn’t even pretend to make an argument; it was entirely mockery.Watching this, I couldn’t help but realize there was a powerful logical argument at the core of the animal rights groups: animals should be treated much the same way humans are — their lives should be respected, their pain minimized, etc.Make this one simple change to your system of morality and everything else falls into place.\n",
    "---\n",
    "Document 3: But I praise people for the good things they do and condemn them for the bad ones.”A final question raised the incrementalism versus revolutionism debate common to all left-wing social movements.Should one really worry about animal treatment when the animals were still going to be killed?Pinger said the answer was undoubtedly yes.\n",
    "---\n",
    "Document 4: They didn’t even pretend to make an argument; it was entirely mockery.Watching this, I couldn’t help but realize there was a powerful logical argument at the core of the animal rights groups: animals should be treated much the same way humans are — their lives should be respected, their pain minimized, etc.Make this one simple change to your system of morality and everything else falls into place.\n",
    "---\n",
    "Document 5: But I praise people for the good things they do and condemn them for the bad ones.”A final question raised the incrementalism versus revolutionism debate common to all left-wing social movements.Should one really worry about animal treatment when the animals were still going to be killed?Pinger said the answer was undoubtedly yes.\n",
    "---\n",
    "Document 6: But it’s been thirty years and vegans are still less than 10% of the population.If you genuinely care about animal suffering, you have to admit that, and say, ‘what else can we do to ease animal suffering?’”After Singer’s talk, I began thinking through the consequences of his morality.A question occurred to me: “Should we also stop animals from eating each other?” I was sure others had made such arguments as *reductio ad absurdums* of vegetarianism, but I thought I might be the first to be genuinely interested in it from a moral perspective.\n",
    "</documents>\n",
    "\n",
    "<answer>\n",
    "\"\"\".strip()\n",
    ")\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e845122-7eb8-4cf4-86c1-2b1306900415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002ece1cc39743df9cfbaddf4a809c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_864f65742b9b4000b165a1bb22f9590c",
      "placeholder": "​",
      "style": "IPY_MODEL_9783987ada9d43df99911f8eebf20308",
      "value": "Map: 100%"
     }
    },
    "53a453362d8d4133ab4e325e3e34878f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71f160de892b4c1ebb25baa54b5614d2",
      "max": 180,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3527aa4065e448b8a60e105cc395545",
      "value": 180
     }
    },
    "6049807d3ceb4a31920f0b0c1a248f7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6820a2af9bf44519fa9c4b3c50200a4",
      "placeholder": "​",
      "style": "IPY_MODEL_bd74c96beddc4ca18c295297ccba750f",
      "value": " 180/180 [00:00&lt;00:00, 309.24 examples/s]"
     }
    },
    "71f160de892b4c1ebb25baa54b5614d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "864f65742b9b4000b165a1bb22f9590c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9783987ada9d43df99911f8eebf20308": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e41ada6a54447b2a2c6d7c69ba9c645": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a33ce0b8245b433089819fecaf8e264e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_002ece1cc39743df9cfbaddf4a809c4c",
       "IPY_MODEL_53a453362d8d4133ab4e325e3e34878f",
       "IPY_MODEL_6049807d3ceb4a31920f0b0c1a248f7b"
      ],
      "layout": "IPY_MODEL_9e41ada6a54447b2a2c6d7c69ba9c645"
     }
    },
    "bd74c96beddc4ca18c295297ccba750f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c3527aa4065e448b8a60e105cc395545": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6820a2af9bf44519fa9c4b3c50200a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
