{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44bc07d-be58-40b9-a938-69ac5afaec90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib64/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib64/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib64/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib64/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib64/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib64/python3.11/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib64/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib64/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib64/python3.11/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: psutil in /usr/local/lib64/python3.11/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib64/python3.11/site-packages (from accelerate) (2.5.1+cu124)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib64/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib64/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib64/python3.11/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib64/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib64/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib64/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib64/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82202b19-b779-4d95-affa-15693da888a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c276e02f-9740-423c-96c9-14df9635800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter huggingface token ········\n"
     ]
    }
   ],
   "source": [
    "token = getpass(prompt=\"enter huggingface token\")\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0379f1-9c86-4d5f-8ef4-757c65d87b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 180 rows in the dataset\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"aaron_data\"\n",
    "   \n",
    "if os.path.isfile(dir_name + '/topics.json'):\n",
    "    with open(dir_name + '/topics.json') as t:\n",
    "        topics = json.load(t)\n",
    "\n",
    "    topics = topics.keys()\n",
    "    tfiles = [dir_name + f\"\"\"/{\"-\".join(t.lower().split(' '))}.json\"\"\" for t in topics]\n",
    "    tfiles = [tf for tf in tfiles if os.path.isfile(tf)]\n",
    "    \n",
    "    data = []\n",
    "    for tf in tfiles:\n",
    "        with open(tf) as t:\n",
    "            data.extend(json.load(t))\n",
    "\n",
    "    print(f'there are {len(data)} rows in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b628c3-5803-4ba9-a0f6-74d8ada72ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdc5998-8d51-409a-91b2-410a968c94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=tfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92ffec3-5e32-4a34-a62d-101ba19fd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row):\n",
    "    row['input'] = f'<question>\\n{row[\"question\"]}\\n</question>\\n\\n<documents>\\n{row[\"documents\"]}\\n</documents>\\n\\n<answer>'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6324a8a-1845-4f50-ad04-4e5ba4402e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac4b2e1107d436b8a3b1a3156f3abcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e1b86f-0664-423c-9f2b-bc90a9d32902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<question>\n",
      "What techniques are most effective for urban gardening in small spaces?\n",
      "</question>\n",
      "\n",
      "<documents>\n",
      "Document 1: Coffee varietals, distinct genetic variants within species like Coffea arabica and Coffea canephora (robusta), significantly influence flavor profiles and growing characteristics. Traditional arabica varietals include Typica (noted for sweet, clean flavors but low yield) and Bourbon (known for complex acidity and moderate body). Hybridization has produced numerous cultivars addressing specific agricultural challenges while maintaining quality attributes. Examples include Caturra, a natural Bourbon mutation with compact growth allowing denser planting; Catuai, combining Mundo Novo's vigor with Caturra's size; and Gesha (or Geisha), an Ethiopian-origin varietal that gained fame after winning the 2004 Panama Cup of Excellence with its distinctive floral and tea-like characteristics. Modern breeding programs increasingly focus on developing varieties combining disease resistance (particularly against coffee leaf rust) and climate resilience while maintaining desirable sensory profiles – a complex challenge given that many pest-resistant cultivars historically sacrificed cup quality for agricultural traits.\n",
      "---\n",
      "Document 2: Coffee storage conditions significantly impact flavor preservation due to coffee's hygroscopic nature and vulnerability to oxidation. Research indicates that the four primary factors affecting degradation are exposure to oxygen, moisture, heat, and light. Whole beans degrade more slowly than ground coffee due to reduced surface area, with sensory studies showing noticeable flavor loss in ground coffee within 15-20 minutes of grinding. Optimal storage maintains beans in airtight containers away from direct light at room temperature (20-25°C), with some research suggesting that freezing beans immediately after roasting can extend peak flavor by inhibiting volatile compound loss. Contrary to popular practice, refrigeration generally harms coffee by causing condensation that accelerates degradation when containers are repeatedly opened. Carbon dioxide release from freshly roasted beans (degassing) creates another storage consideration, requiring either one-way valve packaging or a brief resting period before completely sealing to prevent pressure buildup. Specialty coffee retailers increasingly include roast dates on packaging, with quality-focused businesses generally recommending consumption within 2-4 weeks of roasting for optimal flavor experience.\n",
      "---\n",
      "Document 3: Milk chemistry plays a crucial role in espresso-based beverages, with proteins and fats fundamentally transforming both texture and flavor profiles. During steaming, milk proteins (primarily caseins and whey) denature and form microscopic bubbles that create microfoam, while fats contribute to mouthfeel and flavor integration. Different milk types produce notably different results – whole milk (3.25-4% fat) creates rich, stable foam with sweet flavor characteristics, while skim milk produces stiffer foam but lacks the textural roundness that fat provides. Alternative milks vary significantly in performance: soy protein structures allow reasonable foam formation but often impart distinctive flavors; almond milk typically produces minimal foam due to low protein content unless supplemented with stabilizers; and oat milk has gained barista popularity for performance relatively similar to dairy. Temperature significantly impacts sweetness perception, with lactose reaching peak subjective sweetness around 65°C but becoming increasingly less sweet above 70°C. Modern specialty coffee preparation often emphasizes lower steaming temperatures (55-65°C) compared to traditional Italian practices (70-75°C) to preserve sweetness and prevent scalding flavors, though this remains contentious among different coffee traditions.\n",
      "---\n",
      "Document 4: The sensory experience of coffee follows complex temporal dynamics rather than presenting as a static flavor profile. Professional tasters evaluate this time-based progression through specific terminology describing how flavors evolve from first sip through aftertaste. The initial impression (\"first sip\" or \"attack\") often highlights acids and highly volatile aromatic compounds. The mid-palate experience (\"development\") reveals more complex sugar browning notes and fruit characteristics as the coffee distributes across the palate. The finish or aftertaste can persist for minutes after swallowing and often features more lingering attributes like nuttiness, chocolate notes, or subtle fruit qualities. Temperature progression further transforms the tasting experience, with different compounds becoming more perceptible at different temperature ranges – bright acids and floral notes typically present more clearly at higher temperatures (65-75°C), while sweetness and chocolate characteristics often become more pronounced as coffee cools to 45-55°C. This temperature-dependent evolution explains why professional cupping protocols involve evaluating coffee through a cooling curve rather than at a single temperature point.\n",
      "</documents>\n",
      "\n",
      "<answer>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d49cfde-42ea-450a-8068-3ea15ed912ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6821c8a-7fe5-4e44-8f3b-fdc6e7f6a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c202ab4-67c9-4757-a199-d586daaf1aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb05f9fc-a385-4267-9f2f-5e1f7b695019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(row):\n",
    "    prompt = row[\"input\"]\n",
    "    full_text = prompt + \"\\n\" + f'row[\"answer\"]\\n</answer>'\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        full_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    prompt_tokenized = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False  # Ensure no extra tokens are added\n",
    "    )\n",
    "    prompt_length = len(prompt_tokenized[\"input_ids\"])\n",
    "    \n",
    "    # Copy the tokenized full text to create labels and mask out prompt tokens\n",
    "    labels = tokenized[\"input_ids\"].copy()\n",
    "    labels[:prompt_length] = [-100] * prompt_length  # -100 tells PyTorch to ignore these tokens in loss computation\n",
    "    \n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1df40f-740d-44f7-b1dc-3e2650a9a32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88db3040fee74febad868c36fa63b6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/180 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2af8e2-ae79-4ebb-bc79-7b9add3d0c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 425,984 || all params: 1,236,240,384 || trainable%: 0.0345\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Define LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=4,               # Low-rank dimension\n",
    "    lora_alpha=32,     # Scaling factor\n",
    "    lora_dropout=0.1,  # Dropout for regularization\n",
    "    bias=\"none\",       # No bias training\n",
    "    task_type=\"CAUSAL_LM\"  # Task type: Causal Language Modeling\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70b1ec-58a3-4a67-96c6-62f9135fbc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-06 02:30:46,629] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/gcc-toolset-12/root/usr/libexec/gcc/x86_64-redhat-linux/12/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlvsym'\n",
      "/opt/rh/gcc-toolset-12/root/usr/libexec/gcc/x86_64-redhat-linux/12/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/opt/rh/gcc-toolset-12/root/usr/libexec/gcc/x86_64-redhat-linux/12/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/opt/rh/gcc-toolset-12/root/usr/libexec/gcc/x86_64-redhat-linux/12/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/opt/rh/gcc-toolset-12/root/usr/libexec/gcc/x86_64-redhat-linux/12/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama-1b-finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    use_cpu=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],  # or the appropriate split name\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42f1dd-f184-452a-bb65-143497f89b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
